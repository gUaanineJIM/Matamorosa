{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending '_Moral' to each name using map()\n",
      "['Josefina_Moral', 'Jasmin_Moral', 'Jorjeana_Moral', 'Jorge_Moral', 'Pastisa_Moral', 'Rosefta_Moral', 'Kumaqr_Moral', 'Katherine_Moral', 'Keizny_Moral', 'Kiwran_Moral']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"UseMap\").getOrCreate()\n",
    "\n",
    "# List of names\n",
    "data = [\"Josefina\", \"Jasmin\", \"Jorjeana\", \"Jorge\", \"Pastisa\", \"Rosefta\", \"Kumaqr\", \"Katherine\", \"Keizny\", \"Kiwran\"]\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "rdd_map = rdd.map(lambda s: s + \"_Moral\")\n",
    "result_map = rdd_map.collect()\n",
    "print(\"Appending '_Moral' to each name using map()\")\n",
    "print(result_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter() This keep only names that start with 'K'\n",
      "result: ['Kumaqr_Moral', 'Katherine_Moral', 'Keizny_Moral', 'Kiwran_Moral']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rdd_filter = rdd_map.filter(lambda s: s.startswith('K'))\n",
    "\n",
    "result_filter = rdd_filter.collect()\n",
    "\n",
    "print(\"filter() This keep only names that start with 'K'\")\n",
    "print(\"result:\", result_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatmap() Split the name into one char\n",
      "result: ['K', 'u', 'm', 'a', 'q', 'r', '_', 'M', 'o', 'r', 'a', 'l', 'K', 'a', 't', 'h', 'e', 'r', 'i', 'n', 'e', '_', 'M', 'o', 'r', 'a', 'l', 'K', 'e', 'i', 'z', 'n', 'y', '_', 'M', 'o', 'r', 'a', 'l', 'K', 'i', 'w', 'r', 'a', 'n', '_', 'M', 'o', 'r', 'a', 'l']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rdd_flatmap = rdd_filter.flatMap(lambda s: s)\n",
    "\n",
    "result_flatmap = rdd_flatmap.collect()\n",
    "\n",
    "print(\"Flatmap() Split the name into one char\")\n",
    "print(\"result:\", result_flatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct() transformation: Remove duplicate characters\n",
      "result: ['K', 'u', 'm', 'a', 'q', 'r', '_', 'M', 'o', 'l', 't', 'h', 'e', 'i', 'n', 'z', 'y', 'w']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rdd_distinct = rdd_flatmap.distinct()\n",
    "\n",
    "result_distinct = rdd_distinct.collect()\n",
    "\n",
    "print(\"distinct() transformation: Remove duplicate characters\")\n",
    "print(\"result:\", result_distinct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sortBy() transformation: Sort the distinct characters alphabetically\n",
      "result: ['K', 'M', '_', 'a', 'e', 'h', 'i', 'l', 'm', 'n', 'o', 'q', 'r', 't', 'u', 'w', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rdd_sorted = rdd_distinct.sortBy(lambda s: s)\n",
    "\n",
    "result_sorted = rdd_sorted.collect()\n",
    "\n",
    "print(\"sortBy() transformation: Sort the distinct characters alphabetically\")\n",
    "print(\"result:\", result_sorted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
